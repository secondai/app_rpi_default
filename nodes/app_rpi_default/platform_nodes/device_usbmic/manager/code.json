{
  "type": "code:0.0.1:local:32498h32f2",
  "name": "code",
  "data": {
    "key": "078a6e76-f623-4ae7-8681-f672b2a23c8a",
    "code": "(()=>{\n  return new Promise(async (resolve, reject)=>{\n    try {\n      \n      // Expecting INPUT = device_input_node:Qmf8392h3298h\n      // - capabilityNode: Object,\n      // - externalInputNode: Object,\n\n      // let dataNode = {\n      //   type: 'device_input_node:Qmf8392h3298h',\n      //   data: {\n      //     deviceNode: deviceNode,\n      //     inputNode: {\n      //       type: 'standard_device_action:Qm2398fhsnsf',\n      //       data: {\n      //         action: 'startup',\n      //         options: {}\n      //       }\n      //     }\n      //   }\n      // }\n      \n      // Load the \"Devices\" capability\n      \n      let cmdInputNode = INPUT.data.inputNode;\n\n      if(cmdInputNode.type != 'standard_device_action:Qm2398fhsnsf'){\n        console.log('Unexpected input schema for device input');\n        return reject('Unexpected input schema for device input');\n      }\n      \n      let inputAction = cmdInputNode.data.action;\n      let inputOpts = cmdInputNode.data.options;\n      \n      \n      \n      // Acts similar to \"incoming_from_uni\" \n      // - handles all(?) requests to the device \n      //   - usually passes off to another function \n      \n      // Get settings for device \n      // - expecting consistent relative location \n      let thisNode = await universe.searchMemory({\n        filter: {\n          dataFilter: {\n            _id: SELF._id,\n          }\n        }\n      });\n      thisNode = thisNode[0];\n      let deviceNode = thisNode.parent.parent;\n      let settingsNode = universe.lodash.find(deviceNode.nodes,{type: 'settings:Qmf329ffhj9f823h'});\n      if(!settingsNode){\n        console.error('Missing settings for device', deviceNode.data.name);\n        return reject({});\n      }\n      \n      let googleCredsNode = await universe.searchMemory({\n        filter: {\n          dataFilter: {\n            type: {\n              $like: 'credentials_google:'\n            }\n          }\n        }\n      });\n      googleCredsNode = googleCredsNode.length ? googleCredsNode[0]:null;\n      \n      \n      let snowboyCredsNode = await universe.searchMemory({\n        filter: {\n          dataFilter: {\n            type: {\n              $like: 'credentials_snowboy:'\n            }\n          }\n        }\n      });\n      snowboyCredsNode = snowboyCredsNode.length ? snowboyCredsNode[0]:null;\n      \n      const fs = universe.require('fs');\n      var wav = universe.require('wav');\n      const SharedSpeaker = universe.require('speaker');\n      universe.sharedServices = universe.sharedServices || {};\n      universe.sharedServices.Speaker = universe.sharedServices.Speaker || new SharedSpeaker({\n        channels: 2,          // 2 channels\n        bitDepth: 16,         // 16-bit samples\n        sampleRate: 44100,     // 44,100 Hz sample rate\n        device: 'plug:dmix'\n      });\n      var Speaker = universe.sharedServices.Speaker;\n      \n      const path = universe.require('path');\n\n      const record = universe.require('node-record-lpcm16');\n      const Detector = universe.require('snowboy').Detector;\n      const Models = universe.require('snowboy').Models;\n      \n      var speech = universe.require('@google-cloud/speech'); \n      const { exec, spawn } = universe.require('child_process');\n      \n      \n      \n      let playingSound = false; // TODO: change this shitty locking of aplay \n      \n      async function playSound(eventName){\n        console.log('playSound:', eventName);\n        \n        // // too slow to use loadAndRunCapability ??\n        // await universe.loadAndRunCapability('Speaker',{},{\n        //   type: 'standard_capability_action:0.0.1:local:298j291bs',\n        //   data: {\n        //     action: 'play-sound-for-event',\n        //     options: {\n        //       type: 'generic_event:...',\n        //       data: {\n        //         event: eventName\n        //       }\n        //     }\n        //   }\n        // });\n        \n        // var audioPath = '';\n        // switch(eventName){\n        //   case 'test':\n        //     audioPath = universe.staticFilePath + '/JumpUp.wav';\n        //     break;\n        //   case 'test2':\n        //     audioPath = universe.staticFilePath + '/Hollow.wav';\n        //     break;\n        //   case 'test3':\n        //     audioPath = universe.staticFilePath + '/GentleRoll.wav';\n        //     break;\n            \n        //   case 'ready':\n        //     audioPath = universe.staticFilePath + '/Hollow.wav';\n        //     break;\n        //   case 'processing':\n        //     audioPath = universe.staticFilePath + '/GentleRoll.wav';\n        //     break;\n        //   case 'error':\n        //     audioPath = universe.staticFilePath + '/JumpUp.wav';\n        //     break;\n            \n        //   default:\n        //     console.log('missing audioPath eventName:', eventName);\n        //     // audioPath = universe.staticFilePath + '/Hollow.wav';\n        //     return;\n        // }\n        // // var deviceAddress = \"plughw:CARD=Device_1,DEV=0\";\n        // var deviceAddress = \"plug:dmix\";\n        // exec(`aplay -D ${deviceAddress} ${audioPath}`, (err, stdout, stderr) => {\n        //   playingSound = false;\n        //   if (err) {\n        //     console.error(`exec error: ${err}`);\n        //     return;\n        //   }\n        \n        //   console.log(`aplay output: ${stdout}`);\n        // });\n        \n        // return;\n        \n        // // if(playingSound){\n        // //   universe.setTimeout(()=>{\n        // //     playSound(eventName);\n        // //   },100);\n        // //   return;\n        // // }\n        // // playingSound = true;\n        // universe.sharedServices.AudioMixer = universe.sharedServices.AudioMixer || universe.require('audio-mixer');\n        // var AudioMixer = universe.sharedServices.AudioMixer;\n        \n        // // Creates a new audio mixer with the specified options\n        \n        // universe.sharedServices.mixer = universe.sharedServices.mixer || new AudioMixer.Mixer({\n        //   channels: 2,\n        //   bitDepth: 16,\n        //   sampleRate: 44100,\n        //   clearInterval: 250 // ? \n        // });\n        // var mixer = universe.sharedServices.mixer;\n        // // let mixer = \n        \n        // // Creates an input that is attached to the mixer (diff from standalone??) \n        // let input = mixer.input({\n        //     channels: 2,\n        //     volume: 100\n        // });\n        \n        // // // Creates a standalone input\n        // // let standaloneInput = new AudioMixer.Input({\n        // //   channels: 1,\n        // //   bitDepth: 16,\n        // //   sampleRate: 48000,\n        // //   volume: 75\n        // // });\n        \n        // // Adds the standalone input to the mixer (remove when completed?) \n        // // mixer.addInput(standaloneInput);\n        \n        // // // Pipes a readable stream into an input\n        // // deviceInputStream.pipe(input);\n        // // deviceInputStream2.pipe(standaloneInput);\n        \n        // // Pipes the mixer output to an writable stream\n        // mixer.pipe(Speaker);\n        \n        // var audioPath = '';\n        // switch(eventName){\n        //   case 'ready':\n        //     audioPath = universe.staticFilePath + '/Hollow.wav';\n        //     break;\n        //   case 'processing':\n        //     audioPath = universe.staticFilePath + '/GentleRoll.wav';\n        //     break;\n        //   case 'error':\n        //     audioPath = universe.staticFilePath + '/JumpUp.wav';\n        //     break;\n            \n        //   default:\n        //     audioPath = universe.staticFilePath + '/Hollow.wav';\n        //     break;\n        // }\n        \n        // var wavFile = fs.createReadStream(audioPath);\n        // var wavReader = new wav.Reader();\n        // // the \"format\" event gets emitted at the end of the WAVE header\n        // wavReader.on('format', function (format) {\n         \n        //   // the WAVE header is stripped from the output of the wavReader\n        //   // wavReader.pipe(new Speaker(format));\n        //   console.log('wavFormat tripped');\n        //   wavReader.pipe(input);\n        //   // wavReader.pipe(standaloneInput);\n        // });\n        // wavFile.pipe(wavReader);\n          \n          \n        // var deviceAddress = \"plughw:CARD=Device_1,DEV=0\";\n        // exec(`aplay -D ${deviceAddress} ${audioPath}`, {timeout: 750}, (err, stdout, stderr) => {\n        //   playingSound = false;\n        //   if (err) {\n        //     console.error(`exec error: ${err}`);\n        //     return;\n        //   }\n        \n        //   console.log(`aplay output: ${stdout}`);\n        // });\n      }\n      \n      async function matchTranscript(text){\n        // quick actions \n        switch(text.toLowerCase().split(' ')[0]){\n            \n          case \"start\":\n            \n            let deviceStartServerResult = await universe.loadAndRunCapability('Devices',{},{\n              type: 'standard_capability_action:0.0.1:local:298j291bs',\n              data: {\n                action: 'action',\n                options: {\n                  deviceId: '5b3838c73e8f70001c63f12b',\n                  action: 'start-server',\n                  data: {}\n                }\n              }\n            });\n            \n            console.log('Done with deviceStartServerResult', deviceStartServerResult);\n            return;\n            \n          case \"search\":\n            // playSound();\n            // say something\n            \n            var trackName = text.toLowerCase().split(' ').slice(1).join(' ');\n            \n            if(trackName == 'my fucking jam'){\n              trackName = 'i believe i can fly';\n            }\n            \n            var trackName = 'this is america';\n            console.log('Searching tracks for:', trackName);\n            let deviceFindResult = await universe.loadAndRunCapability('Devices',{},{\n              type: 'standard_capability_action:0.0.1:local:298j291bs',\n              data: {\n                action: 'action',\n                options: {\n                  deviceId: '5b3838c73e8f70001c63f12b',\n                  action: 'spotify-search-tracks',\n                  data: {\n                    type: 'spotify-search-input:Qmsdfljjsdfxsp',\n                    data: {\n                      'any': [trackName]\n                    }\n                  }\n                }\n              }\n            });\n            \n            universe.globalCache.uri = deviceFindResult.data.tracks[0].uri;\n            console.log('Track 0:', deviceFindResult.data.tracks[0]);\n            \n            // console.log('Done with deviceFindResult', deviceFindResult);\n            return;\n            \n            \n          case \"listen\":\n            // playSound();\n            // say something\n            \n            let devicePlayResult = await universe.loadAndRunCapability('Devices',{},{\n              type: 'standard_capability_action:0.0.1:local:298j291bs',\n              data: {\n                action: 'action',\n                options: {\n                  deviceId: '5b3838c73e8f70001c63f12b',\n                  action: 'play-track',\n                  data: {\n                    type: 'track-by-uri:Qmdsfksf',\n                    data: {\n                      uri: universe.globalCache.uri\n                    }\n                  }\n                }\n              }\n            });\n            \n            console.log('Done with devicePlayResult', devicePlayResult);\n            return;\n            \n            // exec(`whoami`, (err, stdout, stderr) => {\n            //   if (err) {\n            //     console.error(`exec error: ${err}`);\n            //     return;\n            //   }\n            \n            //   console.log(`output: ${stdout}`);\n            // });\n            \n            \n            \n            // run mopidy\n            // -only for a little while \n            // exec(`whoami`, (err, stdout, stderr) => {\n            //   if (err) {\n            //     console.error(`exec error: ${err}`);\n            //     return;\n            //   }\n            \n            //   console.log(`output: ${stdout}`);\n            // });\n            \n            // const mopidyProcess = spawn('mopidy', ['--config', path.resolve(universe.staticFilePath + '/mopidy.conf')]);\n            \n            // mopidyProcess.on('error', (err)=>{\n            //   console.log('mopidyProcess error:', err);\n            // })\n            // mopidyProcess.stdout.on('data', (data) => {\n            //   console.log(`mopidy stdout:\\n${data}`);\n            // });\n            \n            // universe.setTimeout(()=>{\n            //   mopidyProcess.kill();\n            // },20 * 1000);\n            \n            // exec(`mopidy --config ${mopidyConfigPath}`, {timeout: 20 * 1000}, (err, stdout, stderr) => {\n            //   if (err) {\n            //     console.error(`exec error: ${err}`);\n            //     return;\n            //   }\n            \n            //   console.log(`mopidy output: ${stdout}`);\n            // });\n            \n            \n          case \"connect bluetooth button\":\n          case \"connect the bluetooth button\":\n          case \"reconnect bluetooth button\":\n          case \"reconnect the bluetooth button\":\n          case \"re-connect bluetooth button\":\n          case \"re-connect the bluetooth button\":\n            await universe.loadAndRunCapability('Devices',{},{\n              type: 'standard_capability_action:0.0.1:local:298j291bs',\n              data: {\n                action: 'reconnect',\n                options: {\n                  deviceId: \"5b340678727763001cd530e9\"\n                }\n              }\n            });\n            break;\n            \n          case \"disconnect bluetooth button\":\n          case \"disconnect the bluetooth button\":\n          case \"dis-connect bluetooth button\":\n          case \"dis-connect the bluetooth button\":\n            await universe.loadAndRunCapability('Devices',{},{\n              type: 'standard_capability_action:0.0.1:local:298j291bs',\n              data: {\n                action: 'disconnect',\n                options: {\n                  deviceId: \"5b340678727763001cd530e9\"\n                }\n              }\n            });\n            break;\n            \n          case \"turn the sprinkler on\":\n          case \"turn the sprinkler off\":\n          case \"turn the sprinklers on\":\n          case \"turn the sprinklers off\":\n            // var sprinklerOnOff = (universe.lodash.last(text.split(' ')) == 'on') ?;\n            await universe.loadAndRunCapability('Devices',{},{\n              type: 'standard_capability_action:0.0.1:local:298j291bs',\n              data: {\n                action: 'input',\n                options: {\n                  deviceId: '5b35507b3c6eca001cc6757d', // sprinkler\n                  action: 'set',\n                  data: {\n            \t\t\t  relay: 0,\n            \t\t\t  status: universe.lodash.last(text.split(' '))\n            \t\t\t}\n                }\n              }\n            });\n            break;\n            \n          default:\n            console.warn(`\n------\nSorry, didn't get that. Please say again. You said: \"${text}\"\n-------`);\n            playSound('error');\n            break;\n        }\n      }\n      \n      // const Sound = universe.require('node-aplay');\n      \n      // var say = universe.require('say');\n      \n      let doneCanWipe;\n              \n              \n      const encoding = 'LINEAR16';\n      const sampleRateHertz = 16000;\n      const languageCode = 'en-US';\n      \n      // Actions \n    \n      switch(inputAction){\n        case 'startup':\n          // check for existence of mic (hardware device profile matches, address exists, etc) \n          console.log('usb mic startup');\n          \n          // listening for hotword, then piping to actual listening \n          \n          let runningRecord = record\n            .start({\n              sampleRateHertz: sampleRateHertz,\n              threshold: 0,\n              // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n              verbose: false,\n              recordProgram: 'arecord', // Try also \"arecord\" or \"sox\" or \"rec\"\n              silence: '10.0',\n              device: 'plughw:CARD=Device,DEV=0'\n            })\n            .on('error', console.error)\n          \n          universe.sharedServices.record = runningRecord;\n          \n      \n          universe.wipeFunc = new Promise(resolve=>{\n            doneCanWipe = resolve;\n          });\n          \n          // start hotword detection! \n          // - happens automatically \n          console.log('Starting hotword detection in 10 seconds');\n          universe.setTimeout(async ()=>{\n            console.log('Starting hotword detection');\n            await universe.loadAndRunCapability('Devices',{},{\n              type: 'standard_capability_action:0.0.1:local:298j291bs',\n              data: {\n                action: 'input',\n                options: {\n                  deviceId: deviceNode._id,\n                  action: 'listen-for-hotword',\n                  data: {}\n                }\n              }\n            });\n            doneCanWipe();\n          },10 * 1000);\n            \n          \n          return resolve({\n            type: 'boolean:Qmdsfdlkj',\n            data: true\n          });\n          break;\n          \n        case 'input':\n          // got some type of input\n          // console.log('inputOpts:', JSON.stringify(inputOpts.action,null,2));\n          \n          switch(inputOpts.action){\n            case 'listen-for-hotword':\n              \n              console.log('Listen for hotword action...', universe.__dirname);\n              \n              universe.wipeFunc = new Promise(resolve=>{\n                doneCanWipe = resolve;\n              });\n              \n              // verify files exist!\n              // - submitting without causes hard exception \n              var resourcePath = path.resolve(universe.__dirname + \"/../node_modules/snowboy/resources/common.res\");\n              console.log('resourcePath:', resourcePath);\n              \n              const models = new Models();\n              \n              models.add({\n                file: universe.staticFilePath + '/jillian.pmdl', // 'resources/models/snowboy.umdl', // staticFilePath + '/jillian.pmdl'\n                sensitivity: '0.45',\n                hotwords : 'jillian'\n              });\n              \n              const detector = new Detector({\n                resource: resourcePath,\n                models: models,\n                audioGain: 2.0,\n                applyFrontend: true\n              });\n              \n              detector.on('silence', function () {\n                // console.log('silence');\n              });\n              \n              detector.on('sound', function (buffer) {\n                // <buffer> contains the last chunk of the audio that triggers the \"sound\"\n                // event. It could be written to a wav stream.\n                console.log('sound');\n              });\n              \n              detector.on('error', function () {\n                console.log('error');\n              });\n              \n              detector.on('hotword', async function (index, hotword, buffer) {\n                // <buffer> contains the last chunk of the audio that triggers the \"hotword\"\n                // event. It could be written to a wav stream. You will have to use it\n                // together with the <buffer> in the \"sound\" event if you want to get audio\n                // data after the hotword.\n                // console.log('--hotword triggered--');\n                // console.log(buffer, buffer.toString());\n                console.log('hotword', index, hotword);\n                    \n                let deviceResult = await universe.loadAndRunCapability('Devices',{},{\n                  type: 'standard_capability_action:0.0.1:local:298j291bs',\n                  data: {\n                    action: 'input',\n                    options: {\n                      deviceId: deviceNode._id,\n                      action: 'listen',\n                      data: {}\n                    }\n                  }\n                });\n            \n              });\n              \n              // record\n              //   .start({\n              //     sampleRateHertz: sampleRateHertz,\n              //     threshold: 0,\n              //     // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n              //     verbose: false,\n              //     recordProgram: 'arecord', // Try also \"arecord\" or \"sox\" or \"rec\"\n              //     silence: '10.0',\n              //     device: 'plughw:CARD=Device,DEV=0'\n              //   })\n              //   .on('error', console.error)\n              //   .pipe(detector);\n              universe.sharedServices.record.pipe(detector);\n            \n\n              // var hotwordTimeout = universe.setTimeout(()=>{\n              //   console.log('stopping hotword mic (timeout)...');\n              //   // record.stop();\n              //   universe.sharedServices.record.unpipe(detector);\n              //   console.log('stopped hotwordmic');\n              //   // playSound('error');\n              //   doneCanWipe();\n              // },10 * 1000);\n              \n              return resolve({\n                type: 'boolean:Qmdsfljk',\n                data: true\n              });\n              \n              break;\n              \n            case 'listen':\n              // starts listening and transcribing \n              // - returns/pipes result, doesn't \"hand off\" to a command, etc. \n              \n              console.log('Starting listen attempt1');\n              \n              // prevent wiping of universe (needed!)\n              universe.wipeFunc = new Promise(resolve=>{\n                doneCanWipe = resolve;\n              });\n              \n              \n              if(!googleCredsNode){\n                console.error('Missing credentials for listening/transcribing via google');\n                return reject({});\n              }\n              \n              // Creates a client\n              const client = new speech.SpeechClient({\n                // apiKey: 'AIzaSyB6KYZNp5LReVN3aSlYGoVXqcfHHdYKmLs',\n                projectId: googleCredsNode.data.project_id,\n                credentials: googleCredsNode.data\n              });\n                          \n              const request = {\n                config: {\n                  encoding: encoding,\n                  sampleRateHertz: sampleRateHertz,\n                  languageCode: languageCode,\n                },\n                interimResults: true, // If you want interim results, set this to true\n              };\n            \n              // Create a recognize stream\n              const recognizeStream = client\n                .streamingRecognize(request)\n                .on('error', console.error)\n                .on('data', async (data) =>{\n                  // console.log(\n                  //   data.results[0] && data.results[0].alternatives[0]\n                  //     ? `Transcription: ${data.results[0].alternatives[0].transcript}\\n`\n                  //     : `\\n\\nReached transcription time limit\\n`\n                  // )\n                  if(data.results && data.results.length){\n                    let result = data.results[0];\n                    // console.log('Results:', JSON.stringify(data.results,null,2));\n                    if(result.isFinal){\n                      console.log('Final:', result.alternatives[0].transcript, result.alternatives[0].confidence)\n                      // makes sure listening stops\n                      console.log('UNPIPE TRANSCRIPTION');\n                      universe.clearTimeout(listenTimeout);\n                      // record.stop();\n                      universe.sharedServices.record.unpipe(recognizeStream);\n                      if(recognizeStream.end){\n                        recognizeStream.end(); // necessary?\n                      } else {\n                        console.error('No .end()');\n                      }\n                      \n                      playSound('processing');\n                      await matchTranscript(result.alternatives[0].transcript);\n                      \n                      // console.log('stopped recording');\n                      \n                      doneCanWipe();\n                    } else {\n                      console.log('Temp:', result.alternatives[0].transcript, result.alternatives[0].confidence);\n                    }\n                  }\n                });\n                \n              // console.log('FUNC:', Object.keys(recognizeStream));\n                \n              // Play the \"we're starting to record\" sound \n              // - we want a simple way of triggering the 'play \"ready\" sound' from the usbspeaker \n              playSound('ready');\n              // universe.setTimeout(()=>{\n              //   playSound('error');\n              // },250);\n              \n              console.log('--Starting Recording!--');\n            \n              // // Start recording and send the microphone input to the Speech API\n              // record\n              //   .start({\n              //     sampleRateHertz: sampleRateHertz,\n              //     threshold: 0,\n              //     // Other options, see https://www.npmjs.com/package/node-record-lpcm16#options\n              //     verbose: false,\n              //     recordProgram: 'arecord', // Try also \"arecord\" or \"sox\" or \"rec\"\n              //     silence: '10.0',\n              //     device: 'plughw:CARD=Device,DEV=0'\n              //   })\n              //   .on('error', console.error)\n              //   .pipe(recognizeStream);\n              universe.sharedServices.record.pipe(recognizeStream);\n            \n\n              var listenTimeout = universe.setTimeout(()=>{\n                console.log('UNPIPE TRANSCRIPTION');\n                // record.stop();\n                universe.sharedServices.record.unpipe(recognizeStream);\n                if(recognizeStream.end){\n                  recognizeStream.end(); // necessary?\n                } else {\n                  console.error('No .end()');\n                }\n                // console.log('stopped');\n                playSound('error');\n                doneCanWipe();\n              },10 * 1000);\n              // var request = {\n              //   config: { \n              //     encoding: 'LINEAR16',\n              //     sampleRateHertz: 16000,\n              //     languageCode: 'en-US'\n              //   },\n              //   singleUtterance: false, \n              //   interimResults: true \n              // }; \n              \n              // var busy = false; \n              // function utterToMe() {\n              //   if (busy == true) { \n              //     return; \n              //   }\n               \n              //   busy = true; \n              //   const arecord = spawn('arecord', ['-f','S16_LE','-r','16000', '-D','plughw:CARD=Device,DEV=0'], {}, () => { console.log(\"Started listening...\"); });\n              \n              \n              //   // Stream the audio to the Google Cloud Speech API\n              //   const recognizeStream = client\n              //     .streamingRecognize(request)\n              //     .on('error', console.error)\n              //     .on('data', data => {\n              //       console.log('Got data');\n              //       if(data.results && \n              //         data.results.length && \n              //         data.results[0].alternatives &&\n              //         data.results[0].alternatives.length){\n              //         console.log(\n              //           `Transcription: ${data.results[0].alternatives[0].transcript}`\n              //         );\n              //       }\n              //       // console.log(\n              //       //   `Transcription: ${data.results[0].alternatives[0].transcript}`\n              //       // );\n              //     });\n              \n              //   // // Stream an audio file from disk to the Speech API, e.g. \"./resources/audio.raw\"\n              //   // fs.createReadStream(filename).pipe(recognizeStream);\n              \n              //   console.log(\"Kicked off transcribing process.\"); \n              //   arecord.stdout.pipe(recognizeStream)\n                \n              //     // .on('error', console.error) \n              //     // .on('data', function(data) { \n              //     //   if (data.results) { \n              //     //     console.log(data.results);\n              //     //   }\n              //     // });\n              \n              //   universe.setTimeout(() => { \n              //     console.log(\"Done with current recognition.\");\n              //     arecord.kill();\n              //     busy = false;\n              //   }, 5000);\n              // }\n              // utterToMe();\n              \n              return resolve({\n                type: 'boolean:Qmdsfljk',\n                data: true\n              });\n            \n            default:\n              console.log('Unhandled inputOpts.action type:', inputOpts.action);\n              break;\n              \n          }\n          return resolve({\n            type: 'boolean:Qmdsfdlkj',\n            data: true\n          });\n          break;\n          \n        default:\n          console.error('Invalid action type:', inputAction);\n          return reject({});\n      }\n        \n    }catch(err){\n      console.error('err managing device:', err);\n      resolve({ERROR: true, err: err.toString()});\n    }\n    \n    \n  })\n})()"
  }
}